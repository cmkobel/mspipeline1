# This profile can be used with a snakemake workflow. Just put this config.yaml-file in a directory called whatever/ and call your snakemake worflow with 
# snakemake --profile whatever/

# ---- Front end stuff ----
local-cores: 16 # front end / head node cores. Most often computing the DAG will be limited by disk-IO anyway.


# ---- Back end stuff ----
cores: 2048 # cluster cores # Fair play.
jobs: 128 # max parallel jobs. Good idea to limit this for dangerous situations.
keep-going: true 
latency-wait: 120 # Some file systems can be slow.

# Flip these for debugging:
keep-incomplete: true # true for development/debugging
rerun-triggers: "mtime" 


# ---- Logging ----
show-failed-logs: true # This one requires additional configuration beyond the scope of this configuration file.
log-handler-script: "scripts/log_handler_script.py"
    


# ---- Conda/Mamba/Apptainer ----
use-conda: true
conda-frontend: 'mamba' # Make sure that you install mamba in the environment where you're calling snakemake. Muuuuch faster than conda.
#use-singularity: true


# ---- Sigma2 Saga SLURM specifics ----

cluster-cancel: "scancel"

cluster:
  sbatch
    --parsable
    --cpus-per-task={threads}
    --mem={resources.mem_mib}
    --job-name=ms-{rule}_{wildcards}
    --output=logs/%j-{jobid}-{rule}.out.log
    --error=logs/%j-{jobid}-{rule}.err.log
    --time={resources.runtime}
    --account=nn9864k
    --partition={resources.partition}

    
# Remove qos from cluster and default-resources to start running with more resources. Devel on sigma is severely limited.


default-resources:
  - mem_mib=1024
  #- disk_mb=1024 # saga doesn't care
  - runtime='12h'
  - tmpdir='$SCRATCH'
  - partition=normal
  
  





# ---- Old unused stuff ----
#cluster: "sbatch -A {cluster.account} -t {cluster.time} -p {cluster.partition} --mem {cluster.mem} --error={cluster.error} --output={cluster.output}"
# drmaa: "
#     --mem={cluster.mem_mib} 
#     --cpus-per-task={cluster.cpus-per-task} 
#     --time={cluster.time} 
#     --account={cluster.account}
#     --error={cluster.error} 
#     --output={cluster.output}
# "
#retries: 2
#cluster: "sbatch --account {cluster.account} --time {cluster.time} --mem {cluster.mem_mib} --error={cluster.error} --output={cluster.output}"

# [--local-cores N] 
#local-cores: 2
#configfile: "configs/workflow.yaml"
#configfile: "config.yaml"
# [--snakefile FILE] 

# While still being possible, cluster configuration has been deprecated by the introduction of Profiles. (https://snakemake.readthedocs.io/en/stable/executing/cli.html#profiles)
#cluster-config: "profiles/slurm/cluster.yaml" 


# ---- Singularity ----
#use-singularity: True
#singularity-prefix: "/faststorage/home/cmkobel/singularity_images/"

