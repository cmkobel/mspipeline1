local-cores: 8 # front end / head node cores
cores: 2048 # cluster cores
jobs: 1000 # max parallel jobs
keep-going: true 
#rerun-incomplete: true
latency-wait: 120
keep-incomplete: true

# This one could be cool to have working 
show-failed-logs: true


# ---- Conda/Mamba ----
use-conda: true
conda-frontend: 'mamba'
conda-prefix: "conda_base/"



# ---- Sigma2 Saga ----

cluster-cancel: "scancel"

cluster:
  mkdir -p logs/old &&
  mv logs/*.log logs/old 2> /dev/null &&
  sbatch
    --parsable
    --cpus-per-task={threads}
    --mem-per-cpu=16384
    --job-name=ms1_{rule}_{wildcards}
    --output=logs/%j-{rule}.out.log
    --error=logs/%j-{rule}.err.log
    --time=12:00:00
    --account=nn9864k
    
set-resources:
  - annotate:mem_mb=65536
  - philosopher_database:mem_mb=65536 # use mem_mb, not mem
  - msfragger:mem_mb=515538 # max on gdk is 515538
  - ionquant:mem_mb=65536




# ---- Old unused stuff ----
#cluster: "sbatch -A {cluster.account} -t {cluster.time} -p {cluster.partition} --mem {cluster.mem} --error={cluster.error} --output={cluster.output}"
# drmaa: "
#     --mem={cluster.mem_mb} 
#     --cpus-per-task={cluster.cpus-per-task} 
#     --time={cluster.time} 
#     --account={cluster.account}
#     --error={cluster.error} 
#     --output={cluster.output}
# "
#retries: 2
#cluster: "sbatch --account {cluster.account} --time {cluster.time} --mem {cluster.mem_mb} --error={cluster.error} --output={cluster.output}"

# [--local-cores N] 
#local-cores: 2
#configfile: "configs/workflow.yaml"
#configfile: "config.yaml"
# [--snakefile FILE] 

# While still being possible, cluster configuration has been deprecated by the introduction of Profiles. (https://snakemake.readthedocs.io/en/stable/executing/cli.html#profiles)
#cluster-config: "profiles/slurm/cluster.yaml" 


# ---- Singularity ----
#use-singularity: True
#singularity-prefix: "/faststorage/home/cmkobel/singularity_images/"